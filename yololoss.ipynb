{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e36a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc83bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv8Loss(nn.Module):\n",
    "    \"\"\"YOLOv8-style loss: Smooth L1 + Binary CE + Cross Entropy\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=37, S=7, lambda_coord=5.0, lambda_obj=1.0, lambda_class=1.0):\n",
    "        super(YOLOv8Loss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.S = S\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_obj = lambda_obj\n",
    "        self.lambda_class = lambda_class\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        \"\"\"\n",
    "        predictions: (batch_size, S*S*(5 + C)) - [x,y,w,h,obj,classes...]\n",
    "        targets: (batch_size, S, S, 5 + C) - [x,y,w,h,conf,classes...]\n",
    "        \"\"\"\n",
    "        batch_size = predictions.size(0)\n",
    "        \n",
    "        # Reshape predictions to match targets\n",
    "        predictions = predictions.view(batch_size, self.S, self.S, 5 + self.num_classes)\n",
    "        \n",
    "        # Split into components\n",
    "        pred_bbox = predictions[..., :4]    # bounding boxes\n",
    "        pred_obj = predictions[..., 4:5]    # objectness\n",
    "        pred_class = predictions[..., 5:]   # classes\n",
    "        \n",
    "        target_bbox = targets[..., :4]\n",
    "        target_obj = targets[..., 4:5]\n",
    "        target_class = targets[..., 5:]\n",
    "        \n",
    "        # Create masks\n",
    "        obj_mask = (target_obj > 0)         # cells with objects\n",
    "        noobj_mask = (target_obj == 0)      # cells without objects\n",
    "        \n",
    "        # 1. Bounding Box Loss (Smooth L1) - only for positive cells\n",
    "        bbox_loss = 0\n",
    "        if obj_mask.sum() > 0:\n",
    "            bbox_loss = F.smooth_l1_loss(\n",
    "                pred_bbox[obj_mask.expand_as(pred_bbox)],\n",
    "                target_bbox[obj_mask.expand_as(target_bbox)],\n",
    "                reduction='sum'\n",
    "            )\n",
    "        \n",
    "        # 2. Objectness Loss (Binary CE)\n",
    "        obj_loss = 0\n",
    "        if obj_mask.sum() > 0:\n",
    "            obj_loss = F.binary_cross_entropy_with_logits(\n",
    "                pred_obj[obj_mask], target_obj[obj_mask], reduction='sum'\n",
    "            )\n",
    "        \n",
    "        noobj_loss = 0\n",
    "        if noobj_mask.sum() > 0:\n",
    "            noobj_loss = F.binary_cross_entropy_with_logits(\n",
    "                pred_obj[noobj_mask], torch.zeros_like(pred_obj[noobj_mask]), reduction='sum'\n",
    "            )\n",
    "        \n",
    "        total_obj_loss = obj_loss + noobj_loss\n",
    "        \n",
    "        # 3. Classification Loss (Cross Entropy) - only for positive cells\n",
    "        class_loss = 0\n",
    "        if obj_mask.sum() > 0:\n",
    "            target_class_indices = torch.argmax(target_class, dim=-1)\n",
    "            obj_mask_flat = obj_mask.squeeze(-1)\n",
    "            \n",
    "            pred_class_obj = pred_class[obj_mask_flat]\n",
    "            target_class_obj = target_class_indices[obj_mask_flat]\n",
    "            \n",
    "            if pred_class_obj.numel() > 0:\n",
    "                class_loss = F.cross_entropy(pred_class_obj, target_class_obj, reduction='sum')\n",
    "        \n",
    "        # Combine losses\n",
    "        total_loss = (\n",
    "            self.lambda_coord * bbox_loss +\n",
    "            self.lambda_obj * total_obj_loss +\n",
    "            self.lambda_class * class_loss\n",
    "        )\n",
    "        \n",
    "        # Normalize by batch size\n",
    "        total_loss = total_loss / batch_size\n",
    "        bbox_loss = bbox_loss / batch_size\n",
    "        total_obj_loss = total_obj_loss / batch_size\n",
    "        class_loss = class_loss / batch_size\n",
    "        \n",
    "        return {\n",
    "            'total_loss': total_loss,\n",
    "            'bbox_loss': bbox_loss,\n",
    "            'obj_loss': total_obj_loss,\n",
    "            'class_loss': class_loss,\n",
    "            'num_pos': obj_mask.sum().item(),\n",
    "            'num_neg': noobj_mask.sum().item()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetPreparer:\n",
    "    \"\"\"Convert dataloader format to YOLO targets\"\"\"\n",
    "    \n",
    "    def __init__(self, S=7, num_classes=37, img_width=640, img_height=160):\n",
    "        self.S = S\n",
    "        self.num_classes = num_classes\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        \"\"\"Convert batch to YOLO target format (need to verify based on json)\"\"\"\n",
    "        batch_size = len(batch['captcha_string'])\n",
    "        targets = torch.zeros(batch_size, self.S, self.S, 5 + self.num_classes)\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            if len(batch['bboxes'][b]) == 0:\n",
    "                continue\n",
    "                \n",
    "            bboxes = batch['bboxes'][b]\n",
    "            category_ids = batch['category_ids'][b]\n",
    "            \n",
    "            for i in range(len(bboxes)):\n",
    "                x1, y1, x2, y2 = bboxes[i]\n",
    "                class_id = category_ids[i].item()\n",
    "                \n",
    "                # Convert to \n",
    "                center_x = (x1 + x2) / 2.0 / self.img_width\n",
    "                center_y = (y1 + y2) / 2.0 / self.img_height\n",
    "                width = (x2 - x1) / self.img_width\n",
    "                height = (y2 - y1) / self.img_height\n",
    "                \n",
    "                # Find grid cell\n",
    "                grid_x = min(max(int(center_x * self.S), 0), self.S - 1)\n",
    "                grid_y = min(max(int(center_y * self.S), 0), self.S - 1)\n",
    "                \n",
    "                # Relative position within grid cell\n",
    "                rel_x = center_x * self.S - grid_x\n",
    "                rel_y = center_y * self.S - grid_y\n",
    "                \n",
    "                # Set target values\n",
    "                targets[b, grid_y, grid_x, 0] = rel_x\n",
    "                targets[b, grid_y, grid_x, 1] = rel_y\n",
    "                targets[b, grid_y, grid_x, 2] = width\n",
    "                targets[b, grid_y, grid_x, 3] = height\n",
    "                targets[b, grid_y, grid_x, 4] = 1.0  # confidence\n",
    "                \n",
    "                # One-hot class\n",
    "                if 0 <= class_id < self.num_classes:\n",
    "                    targets[b, grid_y, grid_x, 5 + class_id] = 1.0\n",
    "        \n",
    "        return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82cb0ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8 Loss Test Results:\n",
      "Total Loss: 44.0681\n",
      "BBox Loss: 0.6995\n",
      "Obj Loss: 39.0235\n",
      "Class Loss: 1.5471\n",
      "Positive samples: 2\n",
      "Negative samples: 194\n"
     ]
    }
   ],
   "source": [
    "# Test with dummy data\n",
    "def test_loss_function():\n",
    "    batch_size = 4\n",
    "    S = 7\n",
    "    num_classes = 37\n",
    "    \n",
    "    # Create dummy predictions and targets\n",
    "    predictions = torch.randn(batch_size, S * S * (5 + num_classes))\n",
    "    targets = torch.zeros(batch_size, S, S, 5 + num_classes)\n",
    "    \n",
    "    # Add dummy objects\n",
    "    targets[0, 2, 3, 4] = 1.0  # object at grid (2,3)\n",
    "    targets[0, 2, 3, 5] = 1.0  # class 0\n",
    "    targets[1, 1, 5, 4] = 1.0  # object at grid (1,5)\n",
    "    targets[1, 1, 5, 10] = 1.0  # class 5\n",
    "    \n",
    "    # Test loss\n",
    "    loss_fn = YOLOv8Loss(num_classes=num_classes, S=S)\n",
    "    loss_dict = loss_fn(predictions, targets)\n",
    "    \n",
    "    print(\"YOLOv8 Loss Test Results:\")\n",
    "    print(f\"Total Loss: {loss_dict['total_loss']:.4f}\")\n",
    "    print(f\"BBox Loss: {loss_dict['bbox_loss']:.4f}\")\n",
    "    print(f\"Obj Loss: {loss_dict['obj_loss']:.4f}\")\n",
    "    print(f\"Class Loss: {loss_dict['class_loss']:.4f}\")\n",
    "    print(f\"Positive samples: {loss_dict['num_pos']}\")\n",
    "    print(f\"Negative samples: {loss_dict['num_neg']}\")\n",
    "    \n",
    "    return loss_dict\n",
    "\n",
    "# Run test\n",
    "test_results = test_loss_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1fe152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test target preparation (if you have dataloader available)\n",
    "def test_target_preparer():\n",
    "    # Example batch format (replace with your actual batch)\n",
    "    dummy_batch = {\n",
    "        'captcha_string': ['ABC', 'XYZ'],\n",
    "        'bboxes': [\n",
    "            torch.tensor([[100, 50, 150, 100], [200, 60, 250, 110]]),  # 2 objects\n",
    "            torch.tensor([[300, 70, 350, 120]])  # 1 object\n",
    "        ],\n",
    "        'category_ids': [\n",
    "            torch.tensor([0, 1]),  # classes for first image\n",
    "            torch.tensor([5])      # class for second image\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    target_preparer = TargetPreparer(S=7, num_classes=37, img_width=640, img_height=160)\n",
    "    targets = target_preparer(dummy_batch)\n",
    "    \n",
    "    print(f\"Target shape: {targets.shape}\")\n",
    "    print(f\"Objects found: {(targets[..., 4] > 0).sum().item()}\")\n",
    "    \n",
    "    # Check first image targets\n",
    "    obj_cells = torch.where(targets[0, ..., 4] > 0)\n",
    "    print(f\"Image 0 - Object cells: {list(zip(obj_cells[0].tolist(), obj_cells[1].tolist()))}\")\n",
    "    \n",
    "    return targets\n",
    "\n",
    "# Run target test\n",
    "# target_results = test_target_preparer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bce0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOTrainer:\n",
    "    \"\"\"Simple training wrapper\"\"\"\n",
    "    \n",
    "    def __init__(self, backbone, yolo_head, loss_fn, target_preparer, device='cuda'):\n",
    "        self.backbone = backbone\n",
    "        self.yolo_head = yolo_head\n",
    "        self.loss_fn = loss_fn\n",
    "        self.target_preparer = target_preparer\n",
    "        self.device = device\n",
    "        \n",
    "        self.backbone.to(device)\n",
    "        self.yolo_head.to(device)\n",
    "        self.loss_fn.to(device)\n",
    "    \n",
    "    def train_step(self, batch, optimizer):\n",
    "        \"\"\"Single training step\"\"\"\n",
    "        self.backbone.train()\n",
    "        self.yolo_head.train()\n",
    "        \n",
    "        images = batch['image'].to(self.device)\n",
    "        targets = self.target_preparer(batch).to(self.device)\n",
    "        \n",
    "        # Forward pass\n",
    "        features = self.backbone(images)\n",
    "        predictions = self.yolo_head(features)\n",
    "        loss_dict = self.loss_fn(predictions, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict['total_loss'].backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return {k: v.item() if torch.is_tensor(v) else v for k, v in loss_dict.items()}\n",
    "    \n",
    "    def validate_step(self, batch):\n",
    "        \"\"\"Single validation step\"\"\"\n",
    "        self.backbone.eval()\n",
    "        self.yolo_head.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            images = batch['image'].to(self.device)\n",
    "            targets = self.target_preparer(batch).to(self.device)\n",
    "            \n",
    "            features = self.backbone(images)\n",
    "            predictions = self.yolo_head(features)\n",
    "            loss_dict = self.loss_fn(predictions, targets)\n",
    "        \n",
    "        return {k: v.item() if torch.is_tensor(v) else v for k, v in loss_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eda9039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "✅ Training setup complete!\n",
      "Ready to integrate with your ResNet-18 backbone and YOLO head\n"
     ]
    }
   ],
   "source": [
    "# Example usage with your models\n",
    "def setup_training():\n",
    "    \"\"\"Setup training components\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Initialize loss and target preparer\n",
    "    loss_fn = YOLOv8Loss(num_classes=37, S=7, lambda_coord=5.0, lambda_obj=1.0, lambda_class=1.0)\n",
    "    target_preparer = TargetPreparer(S=7, num_classes=37, img_width=640, img_height=160)\n",
    "    \n",
    "    # Initialize trainer (uncomment when you have your models)\n",
    "    # trainer = YOLOTrainer(backbone, yolo_head, loss_fn, target_preparer, device)\n",
    "    # optimizer = torch.optim.Adam(\n",
    "    #     list(backbone.parameters()) + list(yolo_head.parameters()), \n",
    "    #     lr=0.001\n",
    "    # )\n",
    "    \n",
    "    print(f\"Device: {device}\")\n",
    "    print(\"✅ Training setup complete!\")\n",
    "    print(\"Ready to integrate with your ResNet-18 backbone and YOLO head\")\n",
    "    \n",
    "    return loss_fn, target_preparer\n",
    "\n",
    "loss_fn, target_preparer = setup_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb398a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
